# üì° Telemetry Analysis Project ‚Äì Deloitte Data Analytics Virtual Simulation

- This project was completed as part of the **Deloitte Data Analytics Virtual Job Simulation** offered through [Forage](https://www.theforage.com/). 
- The purpose of the project is to analyze a client's telemetry data using Excel and Tableau, and present key insights through an interactive dashboard.

---

## üè¢ About Deloitte

- [Deloitte](https://www2.deloitte.com/) is one of the largest professional services firms in the world, offering audit, consulting, financial advisory, risk management, and tax services. 
- Through its virtual job simulations, Deloitte gives aspiring professionals a taste of real-world problems and the chance to develop hands-on skills.

---

## üíº About Forage

[Forage](https://www.theforage.com/) is an online platform that offers free virtual job simulations created by top global companies. 
These experiences allow students and graduates to gain industry-relevant skills, explore career options, and build experience by solving practical tasks.

---

## üìå Project Overview

- As a data analyst working on Deloitte's simulation team, you are tasked with exploring telemetry data collected from a client‚Äôs devices across various factories. 
- Your goal is to clean, analyze, and visualize the data to uncover operational trends and support business decisions.

---

## ‚úÖ Tasks

### Task One ‚Äì Explore Telemetry Data

- Build a dashboard to explore the client's telemetry data  
- Use Excel for data cleaning and Tableau for visualization  
- Deliver actionable insights such as device status, temperature trends, and geographical performance

### Task Two ‚Äì Assist in a Pay Equity Investigation

- Provide support for a fairness analysis in employee pay  
- You can learn more or participate here:  
  üîó [Deloitte Forage Simulation](https://www.theforage.com/simulations/deloitte-au/data-analytics-s5zy)

---


## üìÅ Dataset Info & Description:
Using a data unification algorithm, the tech team at our client, Daikibo, has converted all telemetry data collected from its 4 factories:
- Daikibo Factory Meiyo (Tokyo, Japan)
- Daikibo Factory Seiko (Osaka, Japan)
- Daikibo Berlin (Berlin, Germany)
- Daikibo Shenzhen (Shenzhen, China)

Each location has 9 types of machines, sending a message every 10 mins. Daikibo has been collecting this data for one month (May 2021) and they've shared this data in the form of a single JSON file.



- The telemetry dataset is in **JSON** format and includes data fields such as:

| Field Name      | Description                                  |
|------------------|----------------------------------------------|
| Document Index   | Auto-generated index for each record         |
| Status           | Current status of the device (e.g., online/offline) |
| Temperature      | Temperature readings captured by the device  |
| Device ID        | Unique identifier for each device            |
| Device Type      | Type or model of the device                  |
| Area             | Operational area within the facility         |
| City             | City where the device is located             |
| Country          | Country of operation                         |
| Factory          | Factory name                                 |
| Section          | Section within the factory                   |
| Timestamp        | Date and time of data recording              |
| Unhealthy        | Calculated field indicating performance issues or risks |



---

## üìä Tools Used

- **Excel**: Data exploration, cleaning, and preprocessing  
- **Tableau**: Visualization and dashboard creation  
- **JSON**: Original dataset format  

---


## üì∑ Dashboard Preview
![Dashboard Screenshot](https://github.com/user-attachments/assets/51926cef-e83c-4209-9cae-8acd9135e112)


